"""
å†…ç½®å·¥å…· â€” æ–‡ä»¶æ“ä½œ

read_file, search_text, list_directory, get_file_tree
"""
import asyncio
import fnmatch
import os
import re
from typing import Any, Dict, List, Tuple

import logging

logger = logging.getLogger(__name__)

# ==================== å®‰å…¨é™åˆ¶å¸¸é‡ ====================

# æ•æ„Ÿæ–‡ä»¶/ç›®å½•é»‘åå•
SENSITIVE_PATTERNS = {
    ".env", ".env.local", ".env.production",
    ".git/objects", ".git/refs", ".git/logs",
    "venv", ".venv", "node_modules", "__pycache__",
    "id_rsa", "id_ed25519",
}

SENSITIVE_EXTENSIONS = {
    ".key", ".pem", ".p12", ".pfx", ".jks",
    ".secret", ".credentials",
}

# å…è®¸è¯»å–çš„é…ç½®æ–‡ä»¶
CONFIG_ALLOWLIST = {
    "package.json", "tsconfig.json", "vite.config.ts",
    "docker-compose.yml", "Dockerfile", "nginx.conf",
    "requirements.txt", "pyproject.toml", "setup.cfg",
    "CLAUDE.md", "README.md", "TODO.md",
}

# è¯»å–/æœç´¢é™åˆ¶
MAX_READ_LINES = 200
MAX_SEARCH_RESULTS = 30
SEARCH_CONTEXT_LINES = 1
TOOL_TIMEOUT_SECONDS = 10

# ç›®å½•æ ‘é™åˆ¶
MAX_TREE_DEPTH = 4
TREE_SKIP_DIRS = {
    "node_modules", "__pycache__", ".git", ".venv", "venv",
    "dist", ".claude", "studio-data", "data", ".idea", ".vscode",
    ".mypy_cache", ".pytest_cache", ".ruff_cache", "htmlcov",
    ".next", ".nuxt", "build", "target",
}


# ==================== è·¯å¾„å®‰å…¨æ£€æŸ¥ ====================

def validate_path(workspace: str, rel_path: str) -> Tuple[bool, str, str]:
    """
    éªŒè¯è·¯å¾„å®‰å…¨æ€§

    Returns:
        (is_safe, absolute_path, error_message)
    """
    rel_path = rel_path.strip().lstrip("/")
    abs_path = os.path.realpath(os.path.join(workspace, rel_path))
    workspace_real = os.path.realpath(workspace)
    if not abs_path.startswith(workspace_real + os.sep) and abs_path != workspace_real:
        return False, abs_path, f"âš ï¸ è·¯å¾„è¶Šç•Œ: '{rel_path}' ä¸åœ¨é¡¹ç›®ç›®å½•å†…"
    return True, abs_path, ""


def is_sensitive_file(rel_path: str) -> bool:
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨æ•æ„Ÿé»‘åå•ä¸­"""
    basename = os.path.basename(rel_path)
    _, ext = os.path.splitext(basename)

    if basename in CONFIG_ALLOWLIST:
        return False
    if basename in SENSITIVE_PATTERNS:
        return True
    if ext.lower() in SENSITIVE_EXTENSIONS:
        return True

    path_parts = rel_path.replace("\\", "/").split("/")
    for part in path_parts:
        if part in SENSITIVE_PATTERNS:
            return True
    return False


# ==================== read_file ====================

async def tool_read_file(args: Dict[str, Any], workspace: str) -> str:
    """è¯»å–æ–‡ä»¶å†…å®¹"""
    path = args.get("path", "")
    start_line = args.get("start_line", 1)
    end_line = args.get("end_line")

    if not path:
        return "âš ï¸ è¯·æŒ‡å®šæ–‡ä»¶è·¯å¾„"

    is_safe, abs_path, error = validate_path(workspace, path)
    if not is_safe:
        return error

    if is_sensitive_file(path):
        return f"âš ï¸ æ— æ³•è¯»å–æ•æ„Ÿæ–‡ä»¶: '{path}'"

    if not os.path.exists(abs_path):
        return f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: '{path}'"

    if not os.path.isfile(abs_path):
        return f"âš ï¸ '{path}' ä¸æ˜¯æ–‡ä»¶ (å¯èƒ½æ˜¯ç›®å½•ï¼Œè¯·ä½¿ç”¨ list_directory)"

    file_size = os.path.getsize(abs_path)
    if file_size > 1024 * 1024:
        return f"âš ï¸ æ–‡ä»¶è¿‡å¤§ ({file_size / 1024:.0f}KB)ï¼Œè¯·æŒ‡å®šè¡ŒèŒƒå›´è¯»å–"

    try:
        with open(abs_path, "r", encoding="utf-8", errors="replace") as f:
            lines = f.readlines()
    except UnicodeDecodeError:
        return f"âš ï¸ '{path}' æ˜¯äºŒè¿›åˆ¶æ–‡ä»¶ï¼Œæ— æ³•è¯»å–"

    total_lines = len(lines)
    start = max(1, start_line or 1)
    end = min(total_lines, end_line or (start + MAX_READ_LINES - 1))

    if end - start + 1 > MAX_READ_LINES:
        end = start + MAX_READ_LINES - 1

    selected = lines[start - 1:end]
    content = "".join(selected)

    header = f"ğŸ“„ {path} (è¡Œ {start}-{end}, å…± {total_lines} è¡Œ)"
    if end < total_lines:
        header += f" [æˆªæ–­: ä½¿ç”¨ start_line/end_line æŸ¥çœ‹æ›´å¤š]"

    return f"{header}\n```\n{content}```"


# ==================== search_text ====================

async def tool_search_text(args: Dict[str, Any], workspace: str) -> str:
    """å…¨æ–‡æœç´¢"""
    query = args.get("query", "")
    is_regex = args.get("is_regex", False)
    include_pattern = args.get("include_pattern", "")

    if not query:
        return "âš ï¸ è¯·æŒ‡å®šæœç´¢å†…å®¹"

    cmd = ["grep", "-rn", "--color=never"]
    if is_regex:
        cmd.append("-E")
    else:
        cmd.append("-F")

    cmd.extend(["-B", str(SEARCH_CONTEXT_LINES), "-A", str(SEARCH_CONTEXT_LINES)])
    cmd.extend(["-m", str(MAX_SEARCH_RESULTS)])

    for skip_dir in TREE_SKIP_DIRS:
        cmd.extend(["--exclude-dir", skip_dir])
    for ext in SENSITIVE_EXTENSIONS:
        cmd.extend(["--exclude", f"*{ext}"])
    cmd.extend(["--exclude", ".env*"])

    if include_pattern:
        clean_pattern = include_pattern
        if '/' in clean_pattern:
            clean_pattern = clean_pattern.rsplit('/', 1)[-1]
        if not clean_pattern or clean_pattern == '**':
            clean_pattern = '*'
        cmd.extend(["--include", clean_pattern])

    cmd.append(query)
    cmd.append(".")

    try:
        proc = await asyncio.create_subprocess_exec(
            *cmd, cwd=workspace,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
        )
        stdout, stderr = await asyncio.wait_for(proc.communicate(), timeout=TOOL_TIMEOUT_SECONDS)
        output = stdout.decode("utf-8", errors="replace").strip()

        if not output:
            return f"ğŸ” æœªæ‰¾åˆ°åŒ¹é…: '{query}'"

        output = output.replace("\n./", "\n").lstrip("./")

        MAX_OUTPUT_LINES = 120
        MAX_OUTPUT_CHARS = 6000
        lines = output.split("\n")
        if len(lines) > MAX_OUTPUT_LINES:
            output = "\n".join(lines[:MAX_OUTPUT_LINES])
            output += f"\n\n... (ç»“æœè¿‡å¤šï¼Œå·²æˆªæ–­è‡³ {MAX_OUTPUT_LINES} è¡Œã€‚è¯·ä½¿ç”¨ include_pattern ç¼©å°èŒƒå›´)"
        if len(output) > MAX_OUTPUT_CHARS:
            output = output[:MAX_OUTPUT_CHARS]
            output += f"\n\n... (è¾“å‡ºè¿‡é•¿ï¼Œå·²æˆªæ–­è‡³ {MAX_OUTPUT_CHARS} å­—ç¬¦ã€‚è¯·ç¼©å°æœç´¢èŒƒå›´æˆ–æŒ‡å®š include_pattern)"

        pattern_desc = f"æ­£åˆ™ '{query}'" if is_regex else f"'{query}'"
        scope = f" (èŒƒå›´: {include_pattern})" if include_pattern else ""
        return f"ğŸ” æœç´¢ {pattern_desc}{scope}:\n\n{output}"

    except FileNotFoundError:
        return await _python_search(query, is_regex, include_pattern, workspace)


async def _python_search(
    query: str, is_regex: bool, include_pattern: str, workspace: str,
) -> str:
    """Python å¤‡ç”¨æœç´¢å®ç° (grep ä¸å¯ç”¨æ—¶)"""
    if is_regex:
        try:
            pattern = re.compile(query, re.IGNORECASE)
        except re.error as e:
            return f"âš ï¸ æ— æ•ˆçš„æ­£åˆ™è¡¨è¾¾å¼: {e}"
    else:
        pattern = None

    results: List[str] = []
    count = 0

    for root, dirs, files in os.walk(workspace):
        dirs[:] = [d for d in dirs if d not in TREE_SKIP_DIRS]
        for fname in files:
            if count >= MAX_SEARCH_RESULTS:
                break
            rel_path = os.path.relpath(os.path.join(root, fname), workspace)
            if is_sensitive_file(rel_path):
                continue
            if include_pattern and not fnmatch.fnmatch(fname, include_pattern):
                continue

            try:
                with open(os.path.join(root, fname), "r", encoding="utf-8", errors="replace") as f:
                    file_lines = f.readlines()
            except Exception:
                continue

            for i, line in enumerate(file_lines):
                if count >= MAX_SEARCH_RESULTS:
                    break
                matched = bool(pattern.search(line)) if pattern else (query.lower() in line.lower())
                if matched:
                    count += 1
                    ctx_start = max(0, i - SEARCH_CONTEXT_LINES)
                    ctx_end = min(len(file_lines), i + SEARCH_CONTEXT_LINES + 1)
                    ctx = ""
                    for j in range(ctx_start, ctx_end):
                        prefix = ">" if j == i else " "
                        ctx += f"{prefix} {j+1}: {file_lines[j]}"
                    results.append(f"{rel_path}:{i+1}\n{ctx}")

    if not results:
        return f"ğŸ” æœªæ‰¾åˆ°åŒ¹é…: '{query}'"

    output = "\n---\n".join(results)
    truncated = f"\n\n... (å·²è¾¾åˆ° {MAX_SEARCH_RESULTS} æ¡ä¸Šé™)" if count >= MAX_SEARCH_RESULTS else ""
    return f"ğŸ” æœç´¢ '{query}' æ‰¾åˆ° {count} ä¸ªåŒ¹é…:\n\n{output}{truncated}"


# ==================== list_directory ====================

async def tool_list_directory(args: Dict[str, Any], workspace: str) -> str:
    """åˆ—å‡ºç›®å½•å†…å®¹"""
    path = args.get("path", "")

    is_safe, abs_path, error = validate_path(workspace, path or ".")
    if not is_safe:
        return error

    if not os.path.exists(abs_path):
        return f"âš ï¸ ç›®å½•ä¸å­˜åœ¨: '{path}'"
    if not os.path.isdir(abs_path):
        return f"âš ï¸ '{path}' ä¸æ˜¯ç›®å½• (è¯·ä½¿ç”¨ read_file è¯»å–æ–‡ä»¶)"

    try:
        entries = sorted(os.listdir(abs_path))
    except PermissionError:
        return f"âš ï¸ æ— æƒè®¿é—®: '{path}'"

    entries = [e for e in entries if e not in TREE_SKIP_DIRS and not e.startswith("__pycache__")]

    dirs_list = []
    files_list = []
    for entry in entries:
        full = os.path.join(abs_path, entry)
        if os.path.isdir(full):
            try:
                sub_count = len(os.listdir(full))
            except Exception:
                sub_count = 0
            dirs_list.append(f"ğŸ“ {entry}/ ({sub_count} items)")
        else:
            size = os.path.getsize(full)
            size_str = f"{size}B" if size < 1024 else f"{size / 1024:.1f}KB" if size < 1048576 else f"{size / 1048576:.1f}MB"
            files_list.append(f"ğŸ“„ {entry} ({size_str})")

    display_path = path or "."
    result = f"ğŸ“‚ {display_path}/\n"
    result += "\n".join(dirs_list + files_list)
    if not dirs_list and not files_list:
        result += "(ç©ºç›®å½•)"
    return result


# ==================== get_file_tree ====================

async def tool_get_file_tree(args: Dict[str, Any], workspace: str) -> str:
    """è·å–ç›®å½•æ ‘"""
    path = args.get("path", "")
    max_depth = min(args.get("max_depth", 3), MAX_TREE_DEPTH)

    is_safe, abs_path, error = validate_path(workspace, path or ".")
    if not is_safe:
        return error

    if not os.path.exists(abs_path):
        return f"âš ï¸ è·¯å¾„ä¸å­˜åœ¨: '{path}'"
    if not os.path.isdir(abs_path):
        return f"âš ï¸ '{path}' ä¸æ˜¯ç›®å½•"

    tree = _build_tree(abs_path, max_depth)
    display_path = path or "."
    return f"ğŸŒ³ {display_path}/ ç›®å½•æ ‘ (æ·±åº¦: {max_depth}):\n\n{tree}"


def _build_tree(path: str, max_depth: int, prefix: str = "", depth: int = 0) -> str:
    """é€’å½’æ„å»ºç›®å½•æ ‘"""
    if depth >= max_depth:
        return ""

    try:
        entries = sorted(os.listdir(path))
    except PermissionError:
        return f"{prefix}(æ— æƒé™è®¿é—®)\n"

    entries = [e for e in entries if e not in TREE_SKIP_DIRS and not e.startswith(".")]

    lines = []
    for i, entry in enumerate(entries):
        is_last = i == len(entries) - 1
        connector = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
        full_path = os.path.join(path, entry)

        if os.path.isdir(full_path):
            lines.append(f"{prefix}{connector}{entry}/")
            extension = "    " if is_last else "â”‚   "
            subtree = _build_tree(full_path, max_depth, prefix + extension, depth + 1)
            if subtree:
                lines.append(subtree)
        else:
            lines.append(f"{prefix}{connector}{entry}")

    return "\n".join(lines)
